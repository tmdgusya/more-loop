#!/usr/bin/env bash
set -euo pipefail

# more-loop — Iterative development script wrapping the claude CLI

# Colors
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
BOLD='\033[1m'
NC='\033[0m'

# Defaults
MAX_ITERATIONS=5
MAX_TASKS=""
MODEL="opus"
VERBOSE=false
PROMPT_FILE=""
VERIFY_FILE=""
RESUME_DIR=""
WEB_MODE=false
APPROVE_MODE=false
APPROVE_TIMEOUT=180
WEB_PORT=""

# Shared data directory for web dashboard files
DATA_DIR="${XDG_DATA_HOME:-${HOME}/.local/share}/more-loop"

# Script directory for finding system-prompts in dev mode
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"

load_system_prompt() {
  local name="$1"
  # Dev mode: repo files first
  if [[ -f "${SCRIPT_DIR}/system-prompts/${name}.md" ]]; then
    cat "${SCRIPT_DIR}/system-prompts/${name}.md"
    return
  fi
  # Install mode: DATA_DIR
  if [[ -f "${DATA_DIR}/system-prompts/${name}.md" ]]; then
    cat "${DATA_DIR}/system-prompts/${name}.md"
    return
  fi
  echo ""
}

# State variables for web dashboard
RUN_NAME=""
CURRENT_ITERATION=0
PHASE=""

usage() {
  cat <<'EOF'
Usage: more-loop [OPTIONS] <prompt-file> [verify-file]
       more-loop --resume <run-dir> [OPTIONS]

Arguments:
  prompt-file             Spec/prompt describing what to build
  verify-file             Verification plan (shell script or markdown)
                          If shell script (.sh): runs it, exit 0 = pass
                          If markdown (.md): claude evaluates checklist
                          If omitted: skips verification step

Options:
  -n, --iterations N      Max iterations (default: 5)
  -m, --model MODEL       Model to use (default: opus)
  -v, --verbose           Show full claude output
  -w, --web               Start web dashboard server
  -a, --approve           Enable approval mode (pause after each iteration)
  --approve-timeout N     Approval timeout in seconds (default: 180, 0 = infinite)
  --port PORT             Web server port (default: auto-select)
  --max-tasks N           Max tasks in bootstrap (default: same as iterations, clamped to <= iterations)
  --resume DIR            Resume an interrupted run from its run directory
  -h, --help              Show help
EOF
}

log() {
  echo -e "${BLUE}${BOLD}$1${NC}" >&2
}

log_pass() {
  echo -e "${GREEN}$1${NC}" >&2
}

log_fail() {
  echo -e "${RED}$1${NC}" >&2
}

log_warn() {
  echo -e "${YELLOW}$1${NC}" >&2
}

# Write state.json for web dashboard consumption
write_state_json() {
  local phase="$1"
  local current_task="$2"

  # Count tasks
  local tasks_total=0
  local tasks_completed=0
  if [[ -f "${RUN_DIR}/tasks.md" ]]; then
    tasks_total="$(grep -c '^\- \[.\]' "${RUN_DIR}/tasks.md" 2>/dev/null || true)"
    tasks_completed="$(grep -c '^\- \[x\]' "${RUN_DIR}/tasks.md" 2>/dev/null || true)"
  fi

  # Read files content
  local tasks_content=""
  local acceptance_content=""
  [[ -f "${RUN_DIR}/tasks.md" ]] && tasks_content="$(cat "${RUN_DIR}/tasks.md")"
  [[ -f "${RUN_DIR}/acceptance.md" ]] && acceptance_content="$(cat "${RUN_DIR}/acceptance.md")"

  # If current_task is empty, try to preserve from existing state.json
  if [[ -z "$current_task" ]] && [[ -f "${RUN_DIR}/state.json" ]]; then
    current_task="$(grep -o '"current_task_name":"[^"]*"' "${RUN_DIR}/state.json" 2>/dev/null | cut -d'"' -f4)"
  fi

  # Build iterations array
  local iterations_json="[]"
  if [[ -d "${RUN_DIR}/iterations" ]]; then
    local iter_files=($(ls -1 "${RUN_DIR}/iterations"/*.md 2>/dev/null | sort))
    if [[ ${#iter_files[@]} -gt 0 ]]; then
      iterations_json="["
      local first=true
      for iter_file in "${iter_files[@]}"; do
        local basename
        basename="$(basename "$iter_file")"

        # Parse iteration number from filename
        local iter_num=""
        if [[ "$basename" =~ ^([0-9]+)(-verify)?\.md$ ]]; then
          iter_num="${BASH_REMATCH[1]}"
        fi

        # Skip if we already processed this iteration
        if [[ -n "$iter_num" ]]; then
          local summary=""
          local verify_result=""
          local verify_detail=""

          # Read summary from iteration file
          if [[ "$basename" =~ ^[0-9]+\.md$ ]]; then
            summary="$(cat "$iter_file" | sed 's/"/\\"/g' | tr '\n' ' ')"
          fi

          # Read verify result if exists
          local verify_file="${RUN_DIR}/iterations/${iter_num}-verify.md"
          if [[ -f "$verify_file" ]]; then
            local verify_content
            verify_content="$(cat "$verify_file")"
            if echo "$verify_content" | head -1 | grep -qi "^PASS"; then
              verify_result="PASS"
            elif echo "$verify_content" | head -1 | grep -qi "^FAIL"; then
              verify_result="FAIL"
            else
              verify_result="SKIP"
            fi
            verify_detail="$(echo "$verify_content" | sed 's/"/\\"/g' | tr '\n' ' ')"
          fi

          # Append to JSON array (avoid duplicates)
          if [[ "$first" == true ]]; then
            first=false
          else
            iterations_json="${iterations_json},"
          fi

          iterations_json="${iterations_json}{\"number\":${iter_num},\"summary\":\"${summary}\",\"verify_result\":\"${verify_result}\",\"verify_detail\":\"${verify_detail}\"}"
        fi
      done
      iterations_json="${iterations_json}]"
    fi
  fi

  # Get timestamps
  local started_at=""
  local updated_at
  updated_at="$(date -u +"%Y-%m-%dT%H:%M:%SZ")"

  # Read started_at from existing state if available
  if [[ -f "${RUN_DIR}/state.json" ]]; then
    started_at="$(grep -o '"started_at":"[^"]*"' "${RUN_DIR}/state.json" | cut -d'"' -f4)"
  fi
  if [[ -z "$started_at" ]]; then
    started_at="$updated_at"
  fi

  # Escape strings for JSON
  local run_name_escaped="${RUN_NAME//\"/\\\"}"
  local current_task_escaped="${current_task//\"/\\\"}"
  local phase_escaped="${phase//\"/\\\"}"
  local tasks_content_escaped="${tasks_content//\"/\\\"}"
  tasks_content_escaped="${tasks_content_escaped//$'\n'/\\n}"
  local acceptance_content_escaped="${acceptance_content//\"/\\\"}"
  acceptance_content_escaped="${acceptance_content_escaped//$'\n'/\\n}"

  # Write state.json
  cat > "${RUN_DIR}/state.json" <<EOF
{
  "run_name": "${run_name_escaped}",
  "model": "${MODEL}",
  "max_iterations": ${MAX_ITERATIONS},
  "current_iteration": ${CURRENT_ITERATION},
  "phase": "${phase_escaped}",
  "tasks_total": ${tasks_total},
  "tasks_completed": ${tasks_completed},
  "tasks": "${tasks_content_escaped}",
  "acceptance": "${acceptance_content_escaped}",
  "iterations": ${iterations_json},
  "current_task_name": "${current_task_escaped}",
  "started_at": "${started_at}",
  "updated_at": "${updated_at}"
}
EOF
}

parse_args() {
  while [[ $# -gt 0 ]]; do
    case "$1" in
      -n|--iterations)
        MAX_ITERATIONS="$2"
        shift 2
        ;;
      -m|--model)
        MODEL="$2"
        shift 2
        ;;
      -v|--verbose)
        VERBOSE=true
        shift
        ;;
      -h|--help)
        usage
        exit 0
        ;;
      -w|--web)
        WEB_MODE=true
        shift
        ;;
      -a|--approve)
        APPROVE_MODE=true
        shift
        ;;
      --approve-timeout)
        APPROVE_TIMEOUT="$2"
        shift 2
        ;;
      --max-tasks)
        MAX_TASKS="$2"
        shift 2
        ;;
      --resume)
        RESUME_DIR="$2"
        shift 2
        ;;
      --port)
        WEB_PORT="$2"
        shift 2
        ;;
      -*)
        echo "Unknown option: $1" >&2
        usage >&2
        exit 1
        ;;
      *)
        if [[ -z "$PROMPT_FILE" ]]; then
          PROMPT_FILE="$1"
        elif [[ -z "$VERIFY_FILE" ]]; then
          VERIFY_FILE="$1"
        else
          echo "Unexpected argument: $1" >&2
          usage >&2
          exit 1
        fi
        shift
        ;;
    esac
  done

  # --resume mode: validate run directory
  if [[ -n "$RESUME_DIR" ]]; then
    if [[ ! -d "$RESUME_DIR" ]]; then
      echo "Error: resume directory not found: $RESUME_DIR" >&2
      exit 1
    fi
    if [[ ! -f "$RESUME_DIR/tasks.md" || ! -f "$RESUME_DIR/acceptance.md" ]]; then
      echo "Error: resume directory missing tasks.md or acceptance.md: $RESUME_DIR" >&2
      exit 1
    fi
    # Recover PROMPT_FILE and VERIFY_FILE from the run directory
    if [[ -z "$PROMPT_FILE" && -f "$RESUME_DIR/prompt.md" ]]; then
      PROMPT_FILE="$RESUME_DIR/prompt.md"
    fi
    return
  fi

  if [[ -z "$PROMPT_FILE" ]]; then
    echo "Error: prompt-file is required" >&2
    usage >&2
    exit 1
  fi

  if [[ ! -f "$PROMPT_FILE" ]]; then
    echo "Error: prompt file not found: $PROMPT_FILE" >&2
    exit 1
  fi

  if [[ -n "$VERIFY_FILE" && ! -f "$VERIFY_FILE" ]]; then
    echo "Error: verify file not found: $VERIFY_FILE" >&2
    exit 1
  fi
}

setup_run_dir() {
  local base_name
  base_name="$(basename "$PROMPT_FILE")"
  base_name="${base_name%.*}"

  RUN_DIR=".more-loop/${base_name}"
  RUN_NAME="${base_name}"
  if [[ -d "$RUN_DIR" ]]; then
    RUN_DIR=".more-loop/${base_name}-$(date +%s)"
    RUN_NAME="${base_name}-$(date +%s)"
  fi

  mkdir -p "${RUN_DIR}/iterations"
  cp "$PROMPT_FILE" "${RUN_DIR}/prompt.md"

  if [[ -n "$VERIFY_FILE" ]]; then
    cp "$VERIFY_FILE" "${RUN_DIR}/$(basename "$VERIFY_FILE")"
  fi
}

resume_run_dir() {
  RUN_DIR="$RESUME_DIR"
  RUN_NAME="$(basename "$RUN_DIR")"

  # Find the last completed iteration number
  local last_iter=0
  for f in "${RUN_DIR}"/iterations/[0-9]*.md; do
    [[ -f "$f" ]] || continue
    local basename
    basename="$(basename "$f" .md)"
    # Skip verify files (e.g., 3-verify.md)
    [[ "$basename" =~ -verify$ ]] && continue
    local num="${basename}"
    if [[ "$num" =~ ^[0-9]+$ ]] && [[ "$num" -gt "$last_iter" ]]; then
      last_iter="$num"
    fi
  done

  RESUME_FROM=$((last_iter + 1))
}

run_claude() {
  local prompt="$1"
  local system_prompt="${2:-}"
  local sys_args=()
  [[ -n "$system_prompt" ]] && sys_args=(--append-system-prompt "$system_prompt")

  if [[ "$VERBOSE" == true ]]; then
    echo -e "${YELLOW}━━━ PROMPT ━━━${NC}" >&2
    echo "$prompt" | head -40 >&2
    local prompt_lines
    prompt_lines="$(echo "$prompt" | wc -l)"
    if [[ "$prompt_lines" -gt 40 ]]; then
      echo -e "${YELLOW}... (${prompt_lines} lines total, truncated)${NC}" >&2
    fi
    if [[ -n "$system_prompt" ]]; then
      echo -e "${YELLOW}━━━ SYSTEM PROMPT ━━━${NC}" >&2
      echo "$system_prompt" >&2
    fi
    echo -e "${YELLOW}━━━ CLAUDE OUTPUT ━━━${NC}" >&2
  fi

  local output
  local rc=0

  if [[ "$VERBOSE" == true ]]; then
    # Show claude stdout in real-time on stderr, while still capturing it
    # stderr from claude goes to terminal directly (fd 3 trick avoids merging into $output)
    exec 3>&2
    output="$(claude -p --model "$MODEL" --permission-mode bypassPermissions "${sys_args[@]}" "$prompt" 2>&3 | tee /dev/stderr)" || rc=$?
    exec 3>&-
    echo -e "${YELLOW}━━━ END ━━━${NC}" >&2
  else
    output="$(claude -p --model "$MODEL" --permission-mode bypassPermissions "${sys_args[@]}" "$prompt" 2>/dev/null)" || rc=$?
  fi

  if [[ $rc -ne 0 ]]; then
    log_fail "claude exited with code $rc"
    echo "$output"
    return $rc
  fi

  echo "$output"
}

bootstrap() {
  log "[0/${MAX_ITERATIONS}] Bootstrap — generating tasks and acceptance criteria"

  # Calculate max_tasks — must be <= iterations to be completable
  local max_tasks="${MAX_TASKS}"
  if [[ -z "$max_tasks" ]]; then
    max_tasks="$MAX_ITERATIONS"
  fi
  if [[ "$max_tasks" -gt "$MAX_ITERATIONS" ]]; then
    log_warn "max_tasks (${max_tasks}) > iterations (${MAX_ITERATIONS}), clamping to ${MAX_ITERATIONS}"
    max_tasks="$MAX_ITERATIONS"
  fi

  local spec
  spec="$(cat "$PROMPT_FILE")"

  local sys_prompt
  sys_prompt="$(load_system_prompt bootstrap)"
  sys_prompt="${sys_prompt//\{max_tasks\}/$max_tasks}"

  local prompt
  prompt="$(cat <<EOF
You are bootstrapping an iterative development process.

Read the following spec and produce two files:

1. \`acceptance.md\` — A markdown checklist of acceptance criteria (definition of done).
   Each item should be a \`- [ ]\` checkbox. These are high-level criteria that define success.

2. \`tasks.md\` — A markdown checklist of atomic implementation tasks.
   Each item should be a \`- [ ]\` checkbox. These are concrete, ordered steps to implement the spec.
   Each task should be small enough to complete in a single iteration.
   Order them by dependency (do foundational tasks first).
   Generate NO MORE THAN ${max_tasks} tasks.

Write both files to: ${RUN_DIR}/

Here is the spec:

${spec}
EOF
)"

  local output
  if ! output="$(run_claude "$prompt" "$sys_prompt")"; then
    log_fail "Bootstrap failed"
    echo "$output" > "${RUN_DIR}/iterations/0-bootstrap.md"
    return 1
  fi

  echo "$output" > "${RUN_DIR}/iterations/0-bootstrap.md"

  # Validate bootstrap created required files
  if [[ ! -f "${RUN_DIR}/acceptance.md" ]]; then
    log_fail "Bootstrap failed: acceptance.md not created"
    return 1
  fi
  if [[ ! -f "${RUN_DIR}/tasks.md" ]]; then
    log_fail "Bootstrap failed: tasks.md not created"
    return 1
  fi

  # Enforce max tasks — truncate excess tasks from the checklist
  local task_count
  task_count="$(grep -c '^\- \[ \]' "${RUN_DIR}/tasks.md" 2>/dev/null || true)"
  if [[ "$task_count" -gt "$max_tasks" ]]; then
    log_warn "enforce_max_tasks: Bootstrap generated ${task_count} tasks, truncating to ${max_tasks}"
    local cut_line
    cut_line="$(grep -n '^\- \[ \]' "${RUN_DIR}/tasks.md" | sed -n "$((max_tasks + 1))p" | cut -d: -f1)"
    if [[ -n "$cut_line" ]]; then
      head -n "$((cut_line - 1))" "${RUN_DIR}/tasks.md" > "${RUN_DIR}/tasks.md.tmp"
      mv "${RUN_DIR}/tasks.md.tmp" "${RUN_DIR}/tasks.md"
    fi
  fi

  log_pass "[0/${MAX_ITERATIONS}] Bootstrap complete — $(grep -c '^\- \[ \]' "${RUN_DIR}/tasks.md" || true) tasks"
  if [[ "$WEB_MODE" == "true" ]] || [[ "$APPROVE_MODE" == "true" ]]; then
    write_state_json "bootstrap" ""
  fi
}

count_remaining() {
  if [[ -f "${RUN_DIR}/tasks.md" ]]; then
    grep -c '^\- \[ \]' "${RUN_DIR}/tasks.md" || true
  else
    echo 0
  fi
}

get_next_task_name() {
  grep '^\- \[ \]' "${RUN_DIR}/tasks.md" | head -1 | sed 's/^- \[ \] //'
}

run_task_iteration() {
  local iter="$1"
  local remaining
  remaining="$(count_remaining)"
  local task_name
  task_name="$(get_next_task_name)"

  local retry_info=""
  if [[ -f "${RUN_DIR}/iterations/$((iter - 1))-verify.md" ]]; then
    local prev_verify
    prev_verify="$(cat "${RUN_DIR}/iterations/$((iter - 1))-verify.md")"
    if echo "$prev_verify" | grep -qi "FAIL"; then
      retry_info="The previous attempt FAILED. Here is the verification feedback:

${prev_verify}

Fix the issues before proceeding."
      log_warn "[${iter}/${MAX_ITERATIONS}] Retry: \"${task_name}\" — ${remaining} tasks remaining"
    else
      log "[${iter}/${MAX_ITERATIONS}] Task: \"${task_name}\" — ${remaining} tasks remaining"
    fi
  else
    log "[${iter}/${MAX_ITERATIONS}] Task: \"${task_name}\" — ${remaining} tasks remaining"
  fi

  if [[ "$WEB_MODE" == "true" ]] || [[ "$APPROVE_MODE" == "true" ]]; then
    write_state_json "task" "$task_name"
  fi

  local tasks
  tasks="$(cat "${RUN_DIR}/tasks.md")"
  local acceptance
  acceptance="$(cat "${RUN_DIR}/acceptance.md")"
  local prev_summary=""
  if [[ -f "${RUN_DIR}/iterations/$((iter - 1)).md" ]]; then
    prev_summary="Previous iteration summary:
$(cat "${RUN_DIR}/iterations/$((iter - 1)).md")"
  fi

  local sys_prompt
  sys_prompt="$(load_system_prompt task)"

  local prompt
  prompt="$(cat <<EOF
You are on iteration ${iter} of ${MAX_ITERATIONS} in an iterative development process.

## Current tasks (${remaining} remaining):
${tasks}

## Acceptance criteria:
${acceptance}

${prev_summary}

${retry_info}

## Instructions:
1. Pick the NEXT unchecked task (\`- [ ]\`) from tasks.md
2. Implement it fully
3. Mark it as done by changing \`- [ ]\` to \`- [x]\` in ${RUN_DIR}/tasks.md
4. Write a brief summary of what you did to stdout

Do ONE task only. Be thorough but focused.
EOF
)"

  local output
  if ! output="$(run_claude "$prompt" "$sys_prompt")"; then
    log_fail "[${iter}/${MAX_ITERATIONS}] claude failed during task iteration"
    echo "claude failed with error" > "${RUN_DIR}/iterations/${iter}.md"
    return 1
  fi

  echo "$output" > "${RUN_DIR}/iterations/${iter}.md"
}

run_verify() {
  local iter="$1"

  if [[ -z "$VERIFY_FILE" ]]; then
    log_pass "[${iter}/${MAX_ITERATIONS}] Verify: SKIP (no verify file)"
    echo "SKIP — no verification plan provided" > "${RUN_DIR}/iterations/${iter}-verify.md"
    if [[ "$WEB_MODE" == "true" ]] || [[ "$APPROVE_MODE" == "true" ]]; then
      write_state_json "verify" ""
    fi
    return 0
  fi

  local verify_ext="${VERIFY_FILE##*.}"
  local result
  local rc=0

  if [[ "$verify_ext" == "sh" ]]; then
    # Run shell script verification
    result="$(bash "$VERIFY_FILE" 2>&1)" || rc=$?

    if [[ $rc -eq 0 ]]; then
      log_pass "[${iter}/${MAX_ITERATIONS}] Verify: PASS ✓"
      echo "PASS" > "${RUN_DIR}/iterations/${iter}-verify.md"
      echo "$result" >> "${RUN_DIR}/iterations/${iter}-verify.md"
      if [[ "$VERBOSE" == true ]] && [[ -n "$result" ]]; then
        echo -e "${GREEN}━━━ VERIFY OUTPUT ━━━${NC}" >&2
        echo "$result" >&2
        echo -e "${GREEN}━━━ END ━━━${NC}" >&2
      fi
      if [[ "$WEB_MODE" == "true" ]] || [[ "$APPROVE_MODE" == "true" ]]; then
        write_state_json "verify" ""
      fi
      return 0
    else
      log_fail "[${iter}/${MAX_ITERATIONS}] Verify: FAIL ✗"
      echo "FAIL (exit code ${rc})" > "${RUN_DIR}/iterations/${iter}-verify.md"
      echo "$result" >> "${RUN_DIR}/iterations/${iter}-verify.md"
      if [[ "$VERBOSE" == true ]] && [[ -n "$result" ]]; then
        echo -e "${RED}━━━ VERIFY OUTPUT ━━━${NC}" >&2
        echo "$result" >&2
        echo -e "${RED}━━━ END ━━━${NC}" >&2
      fi
      if [[ "$WEB_MODE" == "true" ]] || [[ "$APPROVE_MODE" == "true" ]]; then
        write_state_json "verify" ""
      fi
      return 1
    fi
  elif [[ "$verify_ext" == "md" ]]; then
    # Use claude to evaluate markdown checklist
    local verify_content
    verify_content="$(cat "$VERIFY_FILE")"
    local iter_summary
    iter_summary="$(cat "${RUN_DIR}/iterations/${iter}.md")"
    local tasks_content
    tasks_content="$(cat "${RUN_DIR}/tasks.md")"

    local prompt
    prompt="$(cat <<EOF
You are a verification agent in an ITERATIVE development process.

## Full verification checklist (for reference):
${verify_content}

## Current task list (checked = done, unchecked = not yet):
${tasks_content}

## Latest iteration summary:
${iter_summary}

## Instructions:
This is an iterative build — NOT all tasks are complete yet.

1. Identify which task was just completed in this iteration
2. Only evaluate checklist items RELEVANT to that specific task
3. Ignore checklist items for features not yet implemented — those are for future iterations

Output exactly one of:
- PASS — if the work done in THIS iteration is correct and doesn't break anything
- FAIL — followed by what specifically is wrong with THIS iteration's work

A task that is correctly implemented should PASS even if unrelated checklist items are still unchecked.
EOF
)"

    if ! result="$(run_claude "$prompt")"; then
      log_fail "[${iter}/${MAX_ITERATIONS}] Verify: ERROR (claude failed)"
      echo "FAIL — claude verification failed" > "${RUN_DIR}/iterations/${iter}-verify.md"
      if [[ "$WEB_MODE" == "true" ]] || [[ "$APPROVE_MODE" == "true" ]]; then
        write_state_json "verify" ""
      fi
      return 1
    fi

    echo "$result" > "${RUN_DIR}/iterations/${iter}-verify.md"

    if echo "$result" | head -5 | grep -qi "^PASS"; then
      log_pass "[${iter}/${MAX_ITERATIONS}] Verify: PASS ✓"
      if [[ "$VERBOSE" == true ]]; then
        echo -e "${GREEN}━━━ VERIFY DETAIL ━━━${NC}" >&2
        echo "$result" >&2
        echo -e "${GREEN}━━━ END ━━━${NC}" >&2
      fi
      if [[ "$WEB_MODE" == "true" ]] || [[ "$APPROVE_MODE" == "true" ]]; then
        write_state_json "verify" ""
      fi
      return 0
    else
      log_fail "[${iter}/${MAX_ITERATIONS}] Verify: FAIL ✗"
      if [[ "$VERBOSE" == true ]]; then
        echo -e "${RED}━━━ VERIFY DETAIL ━━━${NC}" >&2
        echo "$result" >&2
        echo -e "${RED}━━━ END ━━━${NC}" >&2
      fi
      if [[ "$WEB_MODE" == "true" ]] || [[ "$APPROVE_MODE" == "true" ]]; then
        write_state_json "verify" ""
      fi
      return 1
    fi
  else
    log_warn "[${iter}/${MAX_ITERATIONS}] Verify: SKIP (unsupported verify file type: .${verify_ext})"
    echo "SKIP — unsupported verify file type" > "${RUN_DIR}/iterations/${iter}-verify.md"
    if [[ "$WEB_MODE" == "true" ]] || [[ "$APPROVE_MODE" == "true" ]]; then
      write_state_json "verify" ""
    fi
    return 0
  fi
}

revert_last_task() {
  # Find the last checked-off task and uncheck it
  # Uses sed to revert only the LAST [x] match in the file
  local tmpfile
  tmpfile="$(mktemp)"

  # Find the line number of the last [x] task
  local last_checked
  last_checked="$(grep -n '^\- \[x\]' "${RUN_DIR}/tasks.md" | tail -1 | cut -d: -f1)"

  if [[ -n "$last_checked" ]]; then
    sed "${last_checked}s/^- \[x\]/- [ ]/" "${RUN_DIR}/tasks.md" > "$tmpfile"
    mv "$tmpfile" "${RUN_DIR}/tasks.md"
  else
    rm -f "$tmpfile"
  fi
}

enforce_single_task() {
  local snapshot_file="$1"
  local tasks_file="${RUN_DIR}/tasks.md"
  local max_per_iter=3  # allow small batches of related tasks

  local before_count after_count
  before_count="$(grep -c '^\- \[x\]' "$snapshot_file" 2>/dev/null || true)"
  after_count="$(grep -c '^\- \[x\]' "$tasks_file" 2>/dev/null || true)"
  local delta=$(( after_count - before_count ))

  if [[ "$delta" -le "$max_per_iter" ]]; then
    if [[ "$delta" -gt 1 ]]; then
      log_warn "enforce_single_task: Claude checked ${delta} tasks (allowed, max=${max_per_iter})"
    fi
    return 0
  fi

  log_warn "enforce_single_task: Claude checked ${delta} tasks, trimming to ${max_per_iter}"

  # Restore snapshot then check only the first N unchecked tasks
  local unchecked_lines
  unchecked_lines="$(grep -n '^\- \[ \]' "$snapshot_file" | head -"$max_per_iter" | cut -d: -f1)"
  cp "$snapshot_file" "$tasks_file"
  for line_num in $unchecked_lines; do
    sed -i "${line_num}s/^\- \[ \]/- [x]/" "$tasks_file"
  done
}

run_improve_iteration() {
  local iter="$1"

  log "[${iter}/${MAX_ITERATIONS}] Improve mode — all tasks complete"

  local tasks
  tasks="$(cat "${RUN_DIR}/tasks.md")"
  local acceptance
  acceptance="$(cat "${RUN_DIR}/acceptance.md")"
  local prev_summary=""
  if [[ -f "${RUN_DIR}/iterations/$((iter - 1)).md" ]]; then
    prev_summary="Previous iteration summary:
$(cat "${RUN_DIR}/iterations/$((iter - 1)).md")"
  fi

  local sys_prompt
  sys_prompt="$(load_system_prompt improve)"

  local prompt
  prompt="$(cat <<EOF
You are in improvement mode. All planned tasks are complete.

## Completed tasks:
${tasks}

## Acceptance criteria:
${acceptance}

${prev_summary}

## Instructions:
Analyze the codebase. Choose the single most impactful improvement from:
- Simplify complex code
- Refactor for clarity
- Add missing tests
- Improve error handling
- Optimize performance
- Improve documentation

Implement the improvement. Write a brief summary of what you did to stdout.
EOF
)"

  local output
  if ! output="$(run_claude "$prompt" "$sys_prompt")"; then
    log_fail "[${iter}/${MAX_ITERATIONS}] claude failed during improve iteration"
    echo "claude failed with error" > "${RUN_DIR}/iterations/${iter}.md"
    return 1
  fi

  echo "$output" > "${RUN_DIR}/iterations/${iter}.md"
}

# Web server management
SERVER_PID=""

start_web_server() {
  local server_path="${DATA_DIR}/server.py"
  local dashboard_path="${DATA_DIR}/dashboard.html"

  # Check if dashboard files exist
  if [[ ! -f "$server_path" ]]; then
    log_fail "Error: server.py not found at $server_path"
    log_fail "Run 'make link' or './install.sh' to install web dashboard files"
    exit 1
  fi

  if [[ ! -f "$dashboard_path" ]]; then
    log_fail "Error: dashboard.html not found at $dashboard_path"
    log_fail "Run 'make link' or './install.sh' to install web dashboard files"
    exit 1
  fi

  # Build command args
  local server_args=("${RUN_DIR}")
  [[ -n "$WEB_PORT" ]] && server_args+=("$WEB_PORT")

  # Start server in background, capturing stderr to a temp file to get the URL
  local server_stderr
  server_stderr="$(mktemp)"
  python3 "$server_path" "${server_args[@]}" 2>"$server_stderr" &
  SERVER_PID=$!

  # Wait a moment for server to start and print URL
  sleep 1

  # Check if server is still running
  if ! kill -0 "$SERVER_PID" 2>/dev/null; then
    log_fail "Error: Failed to start web server"
    cat "$server_stderr" >&2
    rm -f "$server_stderr"
    exit 1
  fi

  # Get and print the URL
  local dashboard_url
  dashboard_url="$(cat "$server_stderr" | grep -E '^http://' | head -1 || true)"
  rm -f "$server_stderr"

  if [[ -z "$dashboard_url" ]]; then
    # Fallback to default URL format
    local port="${WEB_PORT:-8080}"
    dashboard_url="http://127.0.0.1:${port}"
  fi

  # Set up cleanup trap
  trap "stop_web_server" EXIT SIGINT SIGTERM

  # Save PID for cleanup
  echo "$SERVER_PID" > "${RUN_DIR}/.server.pid"

  # Print dashboard URL
  echo "" >&2
  echo "============================================" >&2
  echo "  Web Dashboard running at:" >&2
  echo "  ${dashboard_url}" >&2
  echo "============================================" >&2
  echo "" >&2
}

stop_web_server() {
  if [[ -n "$SERVER_PID" ]] && kill -0 "$SERVER_PID" 2>/dev/null; then
    kill "$SERVER_PID" 2>/dev/null || true
    wait "$SERVER_PID" 2>/dev/null || true
  fi

  # Also try to kill using saved PID file
  if [[ -f "${RUN_DIR}/.server.pid" ]]; then
    local saved_pid
    saved_pid="$(cat "${RUN_DIR}/.server.pid")"
    if [[ -n "$saved_pid" ]] && kill -0 "$saved_pid" 2>/dev/null; then
      kill "$saved_pid" 2>/dev/null || true
    fi
    rm -f "${RUN_DIR}/.server.pid"
  fi
}

check_stop_signal() {
  # Returns 0 (true) if stop signal file exists
  [[ -f "${RUN_DIR}/.signal-stop" ]]
}

wait_for_approval() {
  local context="$1"  # "bootstrap" or "iteration"

  # Update state to waiting_approval
  if [[ "$WEB_MODE" == "true" ]] || [[ "$APPROVE_MODE" == "true" ]]; then
    write_state_json "waiting_approval" ""
  fi

  local approve_file="${RUN_DIR}/.signal-approve"
  local timeout="${APPROVE_TIMEOUT}"

  # Handle infinite timeout (0)
  if [[ "$timeout" -eq 0 ]]; then
    timeout=999999999
  fi

  log ""
  log "⏸ Approval required: ${context}"
  log ""

  if [[ "$WEB_MODE" == "true" ]]; then
    # Web mode: poll for signal file
    local elapsed=0
    local poll_interval=1

    log "Waiting for approval via web dashboard..."
    log "(Press Ctrl+C to stop)"

    while [[ $elapsed -lt $timeout ]]; do
      # Check for stop signal
      if check_stop_signal; then
        log ""
        log_warn "Stop signal received, exiting..."
        rm -f "${RUN_DIR}/.signal-stop"
        return 1
      fi

      # Check for approve signal
      if [[ -f "$approve_file" ]]; then
        rm -f "$approve_file"
        log_pass "Approved via dashboard, continuing..."
        log ""
        return 0
      fi

      sleep "$poll_interval"
      elapsed=$((elapsed + poll_interval))
    done

    # Timeout reached
    log_warn "Approval timeout (${APPROVE_TIMEOUT}s), auto-continuing..."
    log ""
    return 0

  else
    # Terminal mode: prompt with countdown
    local remaining=$timeout

    log "Press Enter to continue, or Ctrl+C to stop..."
    log "Auto-continue in ${remaining}s"

    # Countdown timer
    while [[ $remaining -gt 0 ]]; do
      # Check for stop signal (if somehow created)
      if check_stop_signal; then
        log ""
        log_warn "Stop signal received, exiting..."
        rm -f "${RUN_DIR}/.signal-stop"
        return 1
      fi

      # Read with timeout (1 second increments)
      if read -r -t 1 -n 1 2>/dev/null; then
        # User pressed a key
        log_pass "Approved via terminal, continuing..."
        log ""
        return 0
      fi

      remaining=$((remaining - 1))
    done

    # Timeout reached
    log_warn "Approval timeout (${APPROVE_TIMEOUT}s), auto-continuing..."
    log ""
    return 0
  fi
}

main() {
  parse_args "$@"

  local start_iter=1

  if [[ -n "$RESUME_DIR" ]]; then
    resume_run_dir
    start_iter="$RESUME_FROM"
    local remaining
    remaining="$(count_remaining)"
    log "Resuming more-loop: ${MAX_ITERATIONS} iterations, model=${MODEL}"
    log "Run directory: ${RUN_DIR}"
    log "Resuming from iteration ${start_iter} — ${remaining} tasks remaining"
  else
    setup_run_dir
    log "Starting more-loop: ${MAX_ITERATIONS} iterations, model=${MODEL}"
    log "Run directory: ${RUN_DIR}"
  fi
  echo "" >&2

  # Start web server if --web flag is set
  if [[ "$WEB_MODE" == "true" ]]; then
    start_web_server
  fi

  # Bootstrap phase (skip on resume)
  if [[ -z "$RESUME_DIR" ]]; then
    if ! bootstrap; then
      log_fail "Bootstrap failed, aborting"
      exit 1
    fi
    echo "" >&2

    # Approval checkpoint after bootstrap
    if [[ "$APPROVE_MODE" == "true" ]]; then
      if ! wait_for_approval "bootstrap"; then
        log "Run stopped by user"
        if [[ "$WEB_MODE" == "true" ]] || [[ "$APPROVE_MODE" == "true" ]]; then
          write_state_json "done" ""
        fi
        exit 0
      fi
    fi
  fi

  # Main loop
  local iter="$start_iter"
  while [[ $iter -le $MAX_ITERATIONS ]]; do
    # Check for stop signal at start of each iteration
    if check_stop_signal; then
      log_warn "Stop signal received, exiting..."
      if [[ "$WEB_MODE" == "true" ]] || [[ "$APPROVE_MODE" == "true" ]]; then
        write_state_json "done" ""
      fi
      rm -f "${RUN_DIR}/.signal-stop"
      exit 0
    fi

    CURRENT_ITERATION="$iter"
    local remaining
    remaining="$(count_remaining)"

    if [[ "$remaining" -gt 0 ]]; then
      # Task mode — snapshot before, enforce after, rollback on verify fail
      cp "${RUN_DIR}/tasks.md" "${RUN_DIR}/.tasks-snapshot.md"
      run_task_iteration "$iter" || true
      enforce_single_task "${RUN_DIR}/.tasks-snapshot.md"

      # Verify
      if ! run_verify "$iter"; then
        # Verification failed — restore tasks.md to pre-iteration state
        # Code changes remain (no git rollback) but checkboxes are fully reverted
        cp "${RUN_DIR}/.tasks-snapshot.md" "${RUN_DIR}/tasks.md"
      fi
      rm -f "${RUN_DIR}/.tasks-snapshot.md"
    else
      # Improvement mode
      run_improve_iteration "$iter" || true

      # Verify improvements too
      run_verify "$iter" || true
    fi

    # Approval checkpoint after each iteration
    if [[ "$APPROVE_MODE" == "true" ]]; then
      if ! wait_for_approval "iteration ${iter}"; then
        log "Run stopped by user"
        if [[ "$WEB_MODE" == "true" ]] || [[ "$APPROVE_MODE" == "true" ]]; then
          write_state_json "done" ""
        fi
        exit 0
      fi
    fi

    echo "" >&2
    iter=$((iter + 1))
  done

  remaining="$(count_remaining)"
  echo "" >&2
  if [[ "$remaining" -eq 0 ]]; then
    log_pass "All tasks complete after ${MAX_ITERATIONS} iterations"
  else
    log_warn "${remaining} tasks remaining after ${MAX_ITERATIONS} iterations"
  fi
  log "Results in: ${RUN_DIR}/"
  if [[ "$WEB_MODE" == "true" ]] || [[ "$APPROVE_MODE" == "true" ]]; then
    write_state_json "done" ""
  fi
}

main "$@"
